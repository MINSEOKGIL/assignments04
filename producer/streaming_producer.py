
import os
import csv
import json
import time
import logging
from kafka import KafkaProducer
from kafka.errors import KafkaError
from datetime import datetime
import re


# âœ… ë¡œê±° ì„¤ì •
def setup_logger():
    logger = logging.getLogger("StreamingProducer")
    logger.setLevel(logging.INFO)
    os.makedirs("logs", exist_ok=True)
    handler = logging.FileHandler("logs/producer.log", mode='a', encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    handler.setFormatter(formatter)

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    if not logger.handlers:
        logger.addHandler(handler)
        logger.addHandler(console_handler)

    return logger


logger = setup_logger()






# âœ… Kafka Producer ìƒì„±
def create_safe_producer():
    try:
        producer = KafkaProducer(
            bootstrap_servers=os.getenv("BOOTSTRAP_SERVERS", "localhost:29092,localhost:29093"),
            key_serializer=lambda k: str(k).encode('utf-8') if k else None,
            value_serializer=lambda v: json.dumps(v).encode("utf-8"),
            retries=5,
            acks='all',
            #ì „ì†¡ ì¤‘ë³µ(ì¬ì‹œë„ ì¤‘ë³µ)ì€ ë°©ì§€í•˜ì§€ë§Œ ë°ì´í„° ë‚´ìš© ì¤‘ë³µì€ ë°©ì§€í•˜ì§€ ì•ŠìŒ.
            enable_idempotence=True,
        
            max_in_flight_requests_per_connection=1,  # idempotence ë³´ì¥ 
        )
        logger.info("âœ… Kafka Producer initialized successfully.")
        return producer
    except Exception as e:
        logger.exception(f"âŒ Failed to initialize Kafka producer: {e}")
        raise


# âœ… Kafka Connect schema
schema = {
    "type": "struct",
    "fields": [
        {"type": "string", "optional": True, "field": "event_time"},
        {"type": "string", "optional": True, "field": "event_type"},
        {"type": "int64", "optional": True, "field": "product_id"},
        {"type": "int64", "optional": True, "field": "category_id"},
        {"type": "string", "optional": True, "field": "category_code"},
        {"type": "string", "optional": True, "field": "brand"},
        {"type": "float", "optional": True, "field": "price"},
        {"type": "int64", "optional": True, "field": "user_id"},
        {"type": "string", "optional": True, "field": "user_session"}
    ],
    "optional": False,
    "name": "user_clickstream_schema"
}


# âœ… ê°œë³„ CSV íŒŒì¼ ì „ì†¡
def stream_csv_file_safe(file_path, topic, producer):
    print(f"\n{'='*80}")
    print(f"ğŸ“‚ íŒŒì¼ ì „ì†¡ ì‹œì‘: {os.path.basename(file_path)}")
    print(f"{'='*80}\n")
    logger.info(f"ğŸ“‚ Start streaming file: {file_path}")

    file_name = os.path.basename(file_path)
    failed_file = f"failed/{file_name}.failed.jsonl"
    os.makedirs("failed", exist_ok=True)

    sent_count = 0
    failed_count = 0
    start_time = time.time()

    def on_error(excp, row=None):
        nonlocal failed_count
        failed_count += 1
        logger.error(f"âŒ Kafka delivery failed: {excp}")
        if row:
            with open(failed_file, 'a', encoding='utf-8') as ff:
                ff.write(json.dumps(row) + '\n')

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)

            for line_num, row in enumerate(reader, start=1):
                try:
                    event_time_raw = row.get("event_time", "")
                    event_time_clean = event_time_raw.replace(" UTC", "").strip() 

                    event = {
                        # "event_time": event_time_clean,  # â† "2019-10-01 00:00:00"
                        "event_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "event_type": row.get("event_type"),
                        "product_id": int(float(row["product_id"])) if row.get("product_id") else None,
                        "category_id": int(float(row["category_id"])) if row.get("category_id") else None,
                        "category_code": row.get("category_code"),
                        "brand": row.get("brand"),
                        "price": float(row["price"]) if row.get("price") else None,
                        "user_id": int(float(row["user_id"])) if row.get("user_id") else None,
                        "user_session": row.get("user_session"),
                    }

                    message = {"schema": schema, "payload": event}
                    product_key = event.get("product_id")

                    producer.send(topic, key=product_key, value=message).add_errback(on_error, row=row)
                    sent_count += 1

                    time.sleep(0.001)  # ì´ˆë‹¹ ì•½ 1000ê±´ ì†ë„ë¡œ ì œí•œ

                    if sent_count % 10000 == 0:
                        print(f"ğŸ“¤ [{datetime.now().strftime('%H:%M:%S')}] {sent_count:,}ê±´ ì „ì†¡ ì™„ë£Œ")

                    if sent_count % 30000 == 0:
                        producer.flush()
                        logger.info(f"Chunk ì™„ë£Œ â€” ëˆ„ì  ì „ì†¡: {sent_count:,}ê±´")

                except (KeyError, ValueError) as e:
                    failed_count += 1
                    if failed_count <= 5:
                        print(f"âš ï¸ ë°ì´í„° ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                    logger.warning(f"âš ï¸ Data error on line {line_num}: {e}")
                    with open(failed_file, 'a', encoding='utf-8') as ff:
                        ff.write(json.dumps(row) + '\n')

                except Exception as e:
                    failed_count += 1
                    print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ (ë¼ì¸ {line_num}): {e}")
                    logger.exception(f"âŒ Unexpected error on line {line_num}: {e}")
                    with open(failed_file, 'a', encoding='utf-8') as ff:
                        ff.write(json.dumps(row) + '\n')

        producer.flush()

        print(f"\n{'='*80}")
        print(f"âœ… íŒŒì¼ ì „ì†¡ ì™„ë£Œ: {file_name}")
        print(f"   - ì´ ì „ì†¡: {sent_count:,}ê°œ")
        print(f"   - ì‹¤íŒ¨: {failed_count}ê°œ")
        print(f"{'='*80}\n")

        logger.info(f"âœ… Completed {file_name}: {sent_count:,} sent, {failed_count} failed")

    except Exception as e:
        logger.exception(f"âŒ Fatal error processing {file_path}: {e}")
        raise


# âœ… í´ë” ë‚´ ëª¨ë“  CSV íŒŒì¼ ìˆœì°¨ ì „ì†¡
def stream_all_csv(csv_dir, topic):
    if not os.path.exists(csv_dir):
        logger.error(f"âŒ Directory not found: {csv_dir}")
        return

    producer = create_safe_producer()

    try:
        files = sorted([f for f in os.listdir(csv_dir) if f.endswith(".csv")], key=lambda x: x)

        print(f"\nğŸ¬ ì „ì†¡ ì‹œì‘!")
        print(f"ğŸ“ ë””ë ‰í† ë¦¬: {csv_dir}")
        print(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
        print(f"ğŸ¯ í† í”½: {topic}\n")
        logger.info(f"ğŸ“ Found {len(files)} CSV files in {csv_dir}")

        for idx, file_name in enumerate(files, 1):
            print(f"\n[{idx}/{len(files)}] íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            file_path = os.path.join(csv_dir, file_name)
            stream_csv_file_safe(file_path, topic, producer)

        print(f"\nğŸ‰ ëª¨ë“  íŒŒì¼ ì „ì†¡ ì™„ë£Œ! ì´ {len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ë¨\n")
        logger.info("ğŸ¯ All CSV files processed successfully.")

    except KeyboardInterrupt:
        print("\nâš ï¸ Ctrl+C ê°ì§€ â†’ ì•ˆì „ ì¢…ë£Œ ì¤‘...")
        logger.warning("âš ï¸ Interrupted by Ctrl+C during CSV streaming")
    
    
    
    except Exception as e:
        logger.exception(f"âŒ Error while processing CSV directory: {e}")
   
    finally:
        try:

            producer.flush()        # ğŸ”¥ ë¬´ì¡°ê±´ ì‹¤í–‰
            producer.close(timeout=30)
        
            print("ğŸ”’ Kafka Producer ì—°ê²° ì¢…ë£Œ")
            logger.info("ğŸ”’ Producer closed safely")
        except Exception as e:
            logger.error(f"âš ï¸ Failed to close producer: {e}")


# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    CSV_DIR = os.getenv("CSV_DIR", "/mnt/c/archive")
    TOPIC_NAME = os.getenv("TOPIC_NAME", "user_clickstream")

    try:
        stream_all_csv(CSV_DIR, TOPIC_NAME)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info("âš ï¸ Interrupted by user")
    except Exception as e:
        logger.exception(f"âŒ Producer terminated unexpectedly: {e}")
