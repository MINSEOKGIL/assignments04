from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.functions import col, count, lit, current_timestamp, min, max
from pyspark.sql.window import Window
from datetime import datetime
import sys
import os
import traceback


# -----------------------------
# 1) Spark Session ìƒì„±
# -----------------------------
def create_spark_session(app_name="Session Behavior Analysis"):
    try:
        spark = (
            SparkSession.builder
            .appName(app_name)
            .master("spark://spark-master:7077")
            .config("spark.jars", "/opt/spark/extra-jars/postgresql-42.7.1.jar")
            .config("spark.sql.adaptive.enabled", "true")
            .config("spark.sql.adaptive.coalescePartitions.enabled", "true")
            .config("spark.executor.memory", "2g")
            .config("spark.driver.memory", "1g")
            .config("spark.executor.cores", "2")
            .getOrCreate()
        )
        spark.sparkContext.setLogLevel("WARN")
        print("âœ… Spark ì„¸ì…˜ ìƒì„± ì™„ë£Œ")
        return spark

    except Exception as e:
        print(f"âŒ Spark ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        raise


# -----------------------------
# 2) PostgreSQL ë°ì´í„° ì½ê¸°
# -----------------------------
def read_clickstream_data(spark, start_date, end_date):

    jdbc_url = "jdbc:postgresql://postgres:5432/clickdb"
    connection_properties = {
        "user":  os.getenv("DB_USER"),
        "password":  os.getenv("DB_USER"),
        "driver": "org.postgresql.Driver"
    }

    # ë‚ ì§œ í˜•ì‹ íŒë‹¨
    if "T" in start_date or " " in start_date:
        start_ts = start_date
        end_ts = end_date
    else:
        start_ts = f"{start_date} 00:00:00"
        end_ts = f"{end_date} 23:59:59"

    print(f"ğŸ“¥ PostgreSQLì—ì„œ Clickstream Data ì½ëŠ” ì¤‘... ({start_ts} ~ {end_ts})")

    try:
        # 1) ì „ì²´ í…Œì´ë¸”ì„ ë¡œë“œ
        df = spark.read.jdbc(
            url=jdbc_url,
            table="user_clickstream",
            properties=connection_properties
        )

        print(f"â¡ï¸ ì „ì²´ Row ìˆ˜: {df.count():,}ê±´")

        # 2) ë‚ ì§œ ì¡°ê±´ í•„í„°ë§ 
        df = df.filter(
            (col("event_time") >= start_ts) &
            (col("event_time") < end_ts)
        )

        # 3) product_id ì—†ëŠ” ë°ì´í„° ì œì™¸
        df = df.filter(col("product_id").isNotNull())

        print(f"ğŸ“‰ ê¸°ê°„ í•„í„°ë§ í›„ Row ìˆ˜: {df.count():,}ê±´")

        # 4) í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df.select(
            "event_time",
            "event_type",
            "product_id",
            "category_code",
            "user_id",
            "user_session"
        )

        print(f"ğŸ“¦ ìµœì¢… ë°˜í™˜ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
        return df

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise

# -----------------------------
# 3) ì„¸ì…˜ í–‰ë™ ë¶„ì„ ìˆ˜í–‰
# -----------------------------
def analyze_sessions(df):

    print("ğŸ” ì„¸ì…˜ í–‰ë™ ë¶„ì„ ì‹œì‘...")

    df = df.cache()

    # ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
    session_time_df = df.groupBy("user_session").agg(
        min("event_time").alias("session_start"),
        max("event_time").alias("session_end")
    ).withColumn(
        "session_length_sec",
        (col("session_end").cast("long") - col("session_start").cast("long"))
    )

    # ì„¸ì…˜ë³„ ì´ë²¤íŠ¸ count(view/cart/purchase)
    event_count_df = df.groupBy("user_session").pivot("event_type").count().fillna(0)

    # ì„¸ì…˜ ê¸°ë°˜ ì „í™˜ ì—¬ë¶€ (purchase 1ê°œë¼ë„ ìˆìœ¼ë©´ ì „í™˜ë¨)
    conversion_df = event_count_df.withColumn(
        "converted",
        F.when(col("purchase") > 0, 1).otherwise(0)
    )

    # ì„¸ì…˜ ê´€ì‹¬ ì¹´í…Œê³ ë¦¬ (ê°€ì¥ ë§ì´ ì¡°íšŒëœ category_code)
    category_df = df.groupBy("user_session", "category_code").count()
    w = Window.partitionBy("user_session").orderBy(F.col("count").desc())

    category_ranked = category_df.withColumn(
        "rank", F.row_number().over(w)
    ).filter("rank = 1").withColumnRenamed("category_code", "interest_category")

    #ê²°ê³¼ ë³‘í•©
    result = (
        session_time_df
        .join(conversion_df, "user_session", "left")
        .join(category_ranked.select("user_session", "interest_category"), "user_session", "left")
    )

    return result


# -----------------------------
# 4) ê²°ê³¼ ì €ì¥
# -----------------------------
def save_session_behavior(result_df, date_str):

    jdbc_url = "jdbc:postgresql://postgres:5432/clickdb"
    connection_properties = {
        "user": os.getenv("DB_USER"),
        "password": os.getenv("DB_PASSWORD"),
        "driver": "org.postgresql.Driver"
    }

    save_df = result_df.withColumn("date", F.to_date(lit(date_str))) \
                       .withColumn("created_at", current_timestamp())

    print("ğŸ’¾ ê²°ê³¼ ì €ì¥ (session_behavior_daily)")

    save_df.write.jdbc(
        url=jdbc_url,
        table="session_behavior_daily",
        mode="append",
        properties=connection_properties
    )

    print(f"âœ… {date_str} ì„¸ì…˜ í–‰ë™ ë¶„ì„ ì €ì¥ ì™„ë£Œ!")


# -----------------------------
# 5) ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------
def run_session_behavior(date_str):
    print(f"\n==============================")
    print(f"ğŸ“… Session Behavior ë¶„ì„ ì‹¤í–‰: {date_str}")
    print(f"==============================\n")

    spark = None

    try:
        spark = create_spark_session(f"Session Behavior - {date_str}")
        df = read_clickstream_data(spark, date_str, date_str)

        if df.count() == 0:
            print(f"âš ï¸ {date_str} ë°ì´í„° ì—†ìŒ.")
            return

        result_df = analyze_sessions(df)

        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ:")
        result_df.show(20, truncate=False)

        save_session_behavior(result_df, date_str)

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        traceback.print_exc()
        raise

    finally:
        if spark:
            spark.stop()


# -----------------------------
# 6) ì§ì ‘ ì‹¤í–‰ ì½”ë“œ
# -----------------------------
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python spark_session_behavior_job.py YYYY-MM-DD")
        sys.exit(1)

    date_str = sys.argv[1]
    run_session_behavior(date_str)
